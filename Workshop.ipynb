{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Face Recognition, but not evil this time\n",
    "\n",
    "Using the faces dataset in:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "faces = fetch_lfw_people(min_faces_per_person=60)\n",
    "```\n",
    "\n",
    "If you use the `faces.target` and `faces.target_names` attributes, you can build a facial recognition algorithm.\n",
    "\n",
    "Use sklearn **gridsearch** (or an equivalent, like random search) to optimize the model for accuracy. Try both a SVM-based classifier and a logistic regression based classifier (with a feature pipeline of your choice) to get the best model. You should have at least 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = fetch_lfw_people(min_faces_per_person=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who are these people?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "       'Gerhard Schroeder', 'Hugo Chavez', 'Junichiro Koizumi',\n",
       "       'Tony Blair'], dtype='<U17')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 3, ..., 7, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(faces['images'][np.random.randint(479)]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 2914)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1348,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate data into X and y\n",
    "X = faces.data; y = faces.target\n",
    "print(X.shape)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()  # instantiate MinMaxScalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the images (i.e. the rows of X)\n",
    "X = np.transpose(scalar.fit_transform(np.transpose(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test partitions and use the test as the holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline with separate grids to eliminate useless recalculations. For example, \"degree\" is only used for kernel=\"poly\" and ignored otherwise. If we use only one universal grid, \"degree\" will be applied to all kernels blindly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('svmmodel', SVC())])\n",
    "\n",
    "param_grid = [\n",
    "    # the linear grid:\n",
    "    {'svmmodel__C': [1, 1E3, 1E6, 1E10],\n",
    "     'svmmodel__kernel': ['linear']},\n",
    "    # the rbf & sigmoid grid:\n",
    "    {'svmmodel__C': [1, 1E3, 1E6, 1E10],\n",
    "     'svmmodel__kernel': ['rbf', 'sigmoid'],\n",
    "     'svmmodel__gamma': ['scale', 'auto']},\n",
    "    # the poly grid:\n",
    "    {'svmmodel__C': [1, 1E3, 1E6, 1E10],\n",
    "     'svmmodel__degree': [3, 4, 5],\n",
    "     'svmmodel__kernel': ['poly'],\n",
    "     'svmmodel__gamma': ['scale', 'auto']}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svmmodel__C': 1000.0, 'svmmodel__gamma': 'auto', 'svmmodel__kernel': 'rbf'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=7, n_jobs=4)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump results in a dataframe just to look at them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(grid.cv_results_).sort_values('mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
       "       'param_svmmodel__C', 'param_svmmodel__kernel', 'param_svmmodel__gamma',\n",
       "       'param_svmmodel__degree', 'params', 'split0_test_score',\n",
       "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
       "       'split4_test_score', 'split5_test_score', 'split6_test_score',\n",
       "       'mean_test_score', 'std_test_score', 'rank_test_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['C', 'kernel', 'gamma', 'degree', 'mean_test_score', 'std_test_score', 'rank_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time',\n",
    "       'C', 'kernel', 'gamma', 'degree', 'params', 'split0_test_score',\n",
    "       'split1_test_score', 'split2_test_score', 'split3_test_score',\n",
    "       'split4_test_score', 'split5_test_score', 'split6_test_score', 'mean_test_score', 'std_test_score',\n",
    "       'rank_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>kernel</th>\n",
       "      <th>gamma</th>\n",
       "      <th>degree</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1e+06</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845649</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1e+10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845649</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>auto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.845649</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835783</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1e+06</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835783</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1e+10</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835783</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.835783</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1e+10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827867</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1000</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827867</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1e+06</td>\n",
       "      <td>rbf</td>\n",
       "      <td>scale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.827867</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C  kernel  gamma degree  mean_test_score  std_test_score  \\\n",
       "14  1e+06     rbf   auto    NaN         0.845649        0.035022   \n",
       "18  1e+10     rbf   auto    NaN         0.845649        0.035022   \n",
       "10   1000     rbf   auto    NaN         0.845649        0.035022   \n",
       "0       1  linear    NaN    NaN         0.835783        0.019623   \n",
       "2   1e+06  linear    NaN    NaN         0.835783        0.019623   \n",
       "3   1e+10  linear    NaN    NaN         0.835783        0.019623   \n",
       "1    1000  linear    NaN    NaN         0.835783        0.019623   \n",
       "16  1e+10     rbf  scale    NaN         0.827867        0.035628   \n",
       "8    1000     rbf  scale    NaN         0.827867        0.035628   \n",
       "12  1e+06     rbf  scale    NaN         0.827867        0.035628   \n",
       "\n",
       "    rank_test_score  \n",
       "14                1  \n",
       "18                1  \n",
       "10                1  \n",
       "0                 4  \n",
       "2                 4  \n",
       "3                 4  \n",
       "1                 4  \n",
       "16                8  \n",
       "8                 8  \n",
       "12                8  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('svmmodel', SVC(C=1000.0, gamma='auto'))])\n",
      "{'svmmodel__C': 1000.0, 'svmmodel__gamma': 'auto', 'svmmodel__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8338278931750742"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelog = Pipeline([\n",
    "\n",
    "    ('pca', PCA()),\n",
    "    ('logreg', LogisticRegression(n_jobs=4,\n",
    "                                  max_iter=2_000,\n",
    "                                  penalty='elasticnet',\n",
    "                                  solver='saga'))\n",
    "])\n",
    "\n",
    "param_grid_log = [\n",
    "    {\n",
    "    'pca__n_components': [50, 100, 150, 200],\n",
    "    'pca__whiten': [True, False],\n",
    "    'pca__svd_solver': ['randomized'],\n",
    "\n",
    "    'logreg__C': [1.0, 10, 100, 10000],\n",
    "    'logreg__l1_ratio': [0.0, 0.3, 0.5, 0.75, 1.0],\n",
    "#        'logreg__l1_ratio': [0., 0.5, 1.0], # chose 0.5\n",
    "#        'logreg__penalty': ['l2'],\n",
    "#        'logreg__dual': [True],\n",
    "#        'logreg__solver': ['saga'],\n",
    "#        'logreg__intercept_scaling': [10],\n",
    "}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 14.1min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 27.5min\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed: 28.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'logreg__C': 1.0,\n",
       " 'logreg__l1_ratio': 0.0,\n",
       " 'pca__n_components': 200,\n",
       " 'pca__svd_solver': 'randomized',\n",
       " 'pca__whiten': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridlog = GridSearchCV(pipelog, param_grid_log, cv=5, n_jobs=4, verbose=3)\n",
    "gridlog.fit(X_train, y_train)\n",
    "gridlog.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('pca', PCA(n_components=200, svd_solver='randomized')),\n",
      "                ('logreg',\n",
      "                 LogisticRegression(l1_ratio=0.0, max_iter=2000, n_jobs=4,\n",
      "                                    penalty='elasticnet', solver='saga'))])\n",
      "{'logreg__C': 1.0, 'logreg__l1_ratio': 0.0, 'pca__n_components': 200, 'pca__svd_solver': 'randomized', 'pca__whiten': False}\n"
     ]
    }
   ],
   "source": [
    "print(gridlog.best_estimator_)\n",
    "print(gridlog.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8308605341246291"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridlog.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Bag of Words, Bag of Popcorn\n",
    "\n",
    "By this point, you are ready for the [Bag of Words, Bag of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition. \n",
    "\n",
    "Use NLP feature pre-processing (using, SKLearn, Gensim, Spacy or Hugginface) to build the best classifier you can. Use a  feature pipeline, and gridsearch for your final model.\n",
    "\n",
    "A succesful project should get 90% or more on a **holdout** dataset you kept for yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of trials\n",
    "### Many tactics were taken. Gensim and TF-IDF were both used along with LGBM. Customized stop words were created starting from the nltk list but these were ultimately not used. Gensim was not in the final version. The code below reflects all of the attempts but the parameter settings are for the final version.\n",
    "### Feature engineering is included in the pipeline in the form of a paragraph segmentation. A Stanford paper found that the critical sentences of a review were at the beginning and ending of a paragraph and so this was varied in an attempt to fish out the sentiment. But in the end, this too did not do so well as the optimized sentence length ended up being pretty much the full paragraph in most cases.\n",
    "### However, I did learn of a method to embed feature engineering into a pipeline and that was worth it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import gensim\n",
    "import gensim.downloader as model_api\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report,plot_confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import lightgbm as lgbm\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Pinhead\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Pinhead\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet');\n",
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('English'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove_from_stop = ['above', 'below', 'up', 'down', 'over', 'under', 'again', \n",
    "                       'more', 'most', 'no', 'not', 'only', 'too', 'very', \"do\", \n",
    "                       \"don't\", 'should', 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", \n",
    "                       'weren', \"weren't\",'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'to', 'from', 'in', 'out', 'on', 'off', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'other', 'some', 'such', 'nor', 'own', 'same', 'so', 'than', 's', 't', 'can', 'will', 'just', 'don', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\"]\n"
     ]
    }
   ],
   "source": [
    "my_stop_words = stopwords.words('English')\n",
    "for w in to_remove_from_stop:\n",
    "    my_stop_words.remove(w)\n",
    "print(my_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Gensim word model (not used in final version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors = model_api.load(\"glove-wiki-gigaword-200\")\n",
    "#word_vectors = model_api.load(\"glove-wiki-gigaword-100\")\n",
    "#word_vectors = model_api.load(\"glove-twitter-100\")\n",
    "#word_vectors = model_api.load(\"glove-twitter-200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table('labeledTrainData.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17618</th>\n",
       "      <td>10073_10</td>\n",
       "      <td>1</td>\n",
       "      <td>One of the great things about many of the supe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7016</th>\n",
       "      <td>8786_8</td>\n",
       "      <td>1</td>\n",
       "      <td>James J. Corbett's autobiography \\The Roar of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11269</th>\n",
       "      <td>1208_9</td>\n",
       "      <td>1</td>\n",
       "      <td>Every kid has that movie that he pops into VHS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311</th>\n",
       "      <td>5144_10</td>\n",
       "      <td>1</td>\n",
       "      <td>This very strange movie is unlike anything mad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23912</th>\n",
       "      <td>2810_4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm surprised about the many female voters who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13088</th>\n",
       "      <td>11569_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Bob Clampett's 'An Itch in Time' milks seven m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14472</th>\n",
       "      <td>655_1</td>\n",
       "      <td>0</td>\n",
       "      <td>I went into this with my hopes up, by twenty m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20906</th>\n",
       "      <td>5431_3</td>\n",
       "      <td>0</td>\n",
       "      <td>This is your typical Priyadarshan movie--a bun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  sentiment                                             review\n",
       "17618  10073_10          1  One of the great things about many of the supe...\n",
       "7016     8786_8          1  James J. Corbett's autobiography \\The Roar of ...\n",
       "11269    1208_9          1  Every kid has that movie that he pops into VHS...\n",
       "7311    5144_10          1  This very strange movie is unlike anything mad...\n",
       "23912    2810_4          0  I'm surprised about the many female voters who...\n",
       "13088   11569_8          1  Bob Clampett's 'An Itch in Time' milks seven m...\n",
       "14472     655_1          0  I went into this with my hopes up, by twenty m...\n",
       "20906    5431_3          0  This is your typical Priyadarshan movie--a bun..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get rid of html and perform other cleaning of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code appears in many sites on internet and I took it and modified it for the stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function that receive a list of words and do lemmatization:\n",
    "def lemma_stem_text(words_list):\n",
    "    # Lemmatizer\n",
    "    # eighties->eight or messages->message or drugs->drug\n",
    "    text = [lemmatizer.lemmatize(token.lower()) for token in words_list]\n",
    "    # going-> go or started->start or watching->watch\n",
    "    text = [lemmatizer.lemmatize(token.lower(), \"v\") for token in text]\n",
    "    return text\n",
    "\n",
    "re_negation = re.compile(\"n't \")\n",
    "\n",
    "# function that receive a sequence of woords and return the same sequence transforming\n",
    "# abbreviated negations to the standard form.\n",
    "def negation_abbreviated_to_standard(sent):\n",
    "    sent = re_negation.sub(\" not \", sent)\n",
    "    return sent\n",
    "\n",
    "def review_to_words(raw_review):\n",
    "    # 1. Remove HTML tags\n",
    "    review_text = BeautifulSoup(raw_review).get_text() \n",
    "\n",
    "    # 2. Transform abbreviated negations to the standard form.\n",
    "    review_text = negation_abbreviated_to_standard(review_text)\n",
    "\n",
    "    # 3. Remove non-letters and non-numbers   \n",
    "    letters_numbers_only = re.sub(\"[^a-zA-Z_0-9]\", \" \", review_text) \n",
    "    \n",
    "    # 4. Convert to lower case and split into individual words (tokenization)\n",
    "    words = np.char.lower(letters_numbers_only.split())                             \n",
    "\n",
    "    # 5. Remove stop words\n",
    "    # stop words not used in final version\n",
    "#    meaningful_words = [w for w in words if not w in my_stop_words]   \n",
    "    meaningful_words = [w for w in words]   \n",
    "\n",
    "    # 6. Apply lemmatization function\n",
    "    lemma_words = lemma_stem_text(meaningful_words)\n",
    "    \n",
    "    # 7. Join the words back into one string separated by space, and return the result.\n",
    "    return( \" \".join(lemma_words))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2488</th>\n",
       "      <th>2489</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with</td>\n",
       "      <td>all</td>\n",
       "      <td>this</td>\n",
       "      <td>stuff</td>\n",
       "      <td>go</td>\n",
       "      <td>down</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>moment</td>\n",
       "      <td>with</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>classic</td>\n",
       "      <td>war</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>world</td>\n",
       "      <td>by</td>\n",
       "      <td>timothy</td>\n",
       "      <td>hines</td>\n",
       "      <td>be</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>start</td>\n",
       "      <td>with</td>\n",
       "      <td>a</td>\n",
       "      <td>manager</td>\n",
       "      <td>nicholas</td>\n",
       "      <td>bell</td>\n",
       "      <td>give</td>\n",
       "      <td>welcome</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>must</td>\n",
       "      <td>be</td>\n",
       "      <td>assume</td>\n",
       "      <td>that</td>\n",
       "      <td>those</td>\n",
       "      <td>who</td>\n",
       "      <td>praise</td>\n",
       "      <td>this</td>\n",
       "      <td>film</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly</td>\n",
       "      <td>trashy</td>\n",
       "      <td>and</td>\n",
       "      <td>wondrously</td>\n",
       "      <td>unpretentious</td>\n",
       "      <td>80</td>\n",
       "      <td>s</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>hooray</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>it</td>\n",
       "      <td>seem</td>\n",
       "      <td>like</td>\n",
       "      <td>more</td>\n",
       "      <td>consideration</td>\n",
       "      <td>ha</td>\n",
       "      <td>go</td>\n",
       "      <td>into</td>\n",
       "      <td>the</td>\n",
       "      <td>imdb</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>i</td>\n",
       "      <td>do</td>\n",
       "      <td>not</td>\n",
       "      <td>believe</td>\n",
       "      <td>they</td>\n",
       "      <td>make</td>\n",
       "      <td>this</td>\n",
       "      <td>film</td>\n",
       "      <td>completely</td>\n",
       "      <td>unnecessary</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy</td>\n",
       "      <td>be</td>\n",
       "      <td>a</td>\n",
       "      <td>loser</td>\n",
       "      <td>ca</td>\n",
       "      <td>not</td>\n",
       "      <td>get</td>\n",
       "      <td>girl</td>\n",
       "      <td>need</td>\n",
       "      <td>to</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>this</td>\n",
       "      <td>30</td>\n",
       "      <td>minute</td>\n",
       "      <td>documentary</td>\n",
       "      <td>bu</td>\n",
       "      <td>uel</td>\n",
       "      <td>make</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>early</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>i</td>\n",
       "      <td>saw</td>\n",
       "      <td>this</td>\n",
       "      <td>movie</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>child</td>\n",
       "      <td>and</td>\n",
       "      <td>it</td>\n",
       "      <td>break</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows  2498 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1       2            3              4        5     \\\n",
       "0          with      all    this        stuff             go     down   \n",
       "1           the  classic     war           of            the    world   \n",
       "2           the     film   start         with              a  manager   \n",
       "3            it     must      be       assume           that    those   \n",
       "4      superbly   trashy     and   wondrously  unpretentious       80   \n",
       "...         ...      ...     ...          ...            ...      ...   \n",
       "24995        it     seem    like         more  consideration       ha   \n",
       "24996         i       do     not      believe           they     make   \n",
       "24997       guy       be       a        loser             ca      not   \n",
       "24998      this       30  minute  documentary             bu      uel   \n",
       "24999         i      saw    this        movie              a        a   \n",
       "\n",
       "           6             7           8            9     ...  2488  2489  2490  \\\n",
       "0            at           the      moment         with  ...  None  None  None   \n",
       "1            by       timothy       hines           be  ...  None  None  None   \n",
       "2      nicholas          bell        give      welcome  ...  None  None  None   \n",
       "3           who        praise        this         film  ...  None  None  None   \n",
       "4             s  exploitation      hooray          the  ...  None  None  None   \n",
       "...         ...           ...         ...          ...  ...   ...   ...   ...   \n",
       "24995        go          into         the         imdb  ...  None  None  None   \n",
       "24996      this          film  completely  unnecessary  ...  None  None  None   \n",
       "24997       get          girl        need           to  ...  None  None  None   \n",
       "24998      make            in         the        early  ...  None  None  None   \n",
       "24999     child           and          it        break  ...  None  None  None   \n",
       "\n",
       "       2491  2492  2493  2494  2495  2496  2497  \n",
       "0      None  None  None  None  None  None  None  \n",
       "1      None  None  None  None  None  None  None  \n",
       "2      None  None  None  None  None  None  None  \n",
       "3      None  None  None  None  None  None  None  \n",
       "4      None  None  None  None  None  None  None  \n",
       "...     ...   ...   ...   ...   ...   ...   ...  \n",
       "24995  None  None  None  None  None  None  None  \n",
       "24996  None  None  None  None  None  None  None  \n",
       "24997  None  None  None  None  None  None  None  \n",
       "24998  None  None  None  None  None  None  None  \n",
       "24999  None  None  None  None  None  None  None  \n",
       "\n",
       "[25000 rows x 2498 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = df.review.apply(review_to_words).str.split()\n",
    "words = pd.DataFrame(words.tolist())\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# see how long (word count) are the reviews\n",
    "is_missing = words.isna().values\n",
    "# first Nan is the location where the first None appears \n",
    "# hence, the end of the review.\n",
    "first_nan = np.where(is_missing.any(1), is_missing.argmax(1), np.nan)\n",
    "plt.hist(first_nan,bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new dataframe like \"words\" but with an additional column that represents the number of non-Nan columns in each row. Call this column frst_nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2489</th>\n",
       "      <th>2490</th>\n",
       "      <th>2491</th>\n",
       "      <th>2492</th>\n",
       "      <th>2493</th>\n",
       "      <th>2494</th>\n",
       "      <th>2495</th>\n",
       "      <th>2496</th>\n",
       "      <th>2497</th>\n",
       "      <th>frst_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with</td>\n",
       "      <td>all</td>\n",
       "      <td>this</td>\n",
       "      <td>stuff</td>\n",
       "      <td>go</td>\n",
       "      <td>down</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>moment</td>\n",
       "      <td>with</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>classic</td>\n",
       "      <td>war</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>world</td>\n",
       "      <td>by</td>\n",
       "      <td>timothy</td>\n",
       "      <td>hines</td>\n",
       "      <td>be</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>film</td>\n",
       "      <td>start</td>\n",
       "      <td>with</td>\n",
       "      <td>a</td>\n",
       "      <td>manager</td>\n",
       "      <td>nicholas</td>\n",
       "      <td>bell</td>\n",
       "      <td>give</td>\n",
       "      <td>welcome</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it</td>\n",
       "      <td>must</td>\n",
       "      <td>be</td>\n",
       "      <td>assume</td>\n",
       "      <td>that</td>\n",
       "      <td>those</td>\n",
       "      <td>who</td>\n",
       "      <td>praise</td>\n",
       "      <td>this</td>\n",
       "      <td>film</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>superbly</td>\n",
       "      <td>trashy</td>\n",
       "      <td>and</td>\n",
       "      <td>wondrously</td>\n",
       "      <td>unpretentious</td>\n",
       "      <td>80</td>\n",
       "      <td>s</td>\n",
       "      <td>exploitation</td>\n",
       "      <td>hooray</td>\n",
       "      <td>the</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24995</th>\n",
       "      <td>it</td>\n",
       "      <td>seem</td>\n",
       "      <td>like</td>\n",
       "      <td>more</td>\n",
       "      <td>consideration</td>\n",
       "      <td>ha</td>\n",
       "      <td>go</td>\n",
       "      <td>into</td>\n",
       "      <td>the</td>\n",
       "      <td>imdb</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24996</th>\n",
       "      <td>i</td>\n",
       "      <td>do</td>\n",
       "      <td>not</td>\n",
       "      <td>believe</td>\n",
       "      <td>they</td>\n",
       "      <td>make</td>\n",
       "      <td>this</td>\n",
       "      <td>film</td>\n",
       "      <td>completely</td>\n",
       "      <td>unnecessary</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24997</th>\n",
       "      <td>guy</td>\n",
       "      <td>be</td>\n",
       "      <td>a</td>\n",
       "      <td>loser</td>\n",
       "      <td>ca</td>\n",
       "      <td>not</td>\n",
       "      <td>get</td>\n",
       "      <td>girl</td>\n",
       "      <td>need</td>\n",
       "      <td>to</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>this</td>\n",
       "      <td>30</td>\n",
       "      <td>minute</td>\n",
       "      <td>documentary</td>\n",
       "      <td>bu</td>\n",
       "      <td>uel</td>\n",
       "      <td>make</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>early</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>i</td>\n",
       "      <td>saw</td>\n",
       "      <td>this</td>\n",
       "      <td>movie</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>child</td>\n",
       "      <td>and</td>\n",
       "      <td>it</td>\n",
       "      <td>break</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000 rows  2499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1       2            3              4        5  \\\n",
       "0          with      all    this        stuff             go     down   \n",
       "1           the  classic     war           of            the    world   \n",
       "2           the     film   start         with              a  manager   \n",
       "3            it     must      be       assume           that    those   \n",
       "4      superbly   trashy     and   wondrously  unpretentious       80   \n",
       "...         ...      ...     ...          ...            ...      ...   \n",
       "24995        it     seem    like         more  consideration       ha   \n",
       "24996         i       do     not      believe           they     make   \n",
       "24997       guy       be       a        loser             ca      not   \n",
       "24998      this       30  minute  documentary             bu      uel   \n",
       "24999         i      saw    this        movie              a        a   \n",
       "\n",
       "              6             7           8            9  ...  2489  2490  2491  \\\n",
       "0            at           the      moment         with  ...  None  None  None   \n",
       "1            by       timothy       hines           be  ...  None  None  None   \n",
       "2      nicholas          bell        give      welcome  ...  None  None  None   \n",
       "3           who        praise        this         film  ...  None  None  None   \n",
       "4             s  exploitation      hooray          the  ...  None  None  None   \n",
       "...         ...           ...         ...          ...  ...   ...   ...   ...   \n",
       "24995        go          into         the         imdb  ...  None  None  None   \n",
       "24996      this          film  completely  unnecessary  ...  None  None  None   \n",
       "24997       get          girl        need           to  ...  None  None  None   \n",
       "24998      make            in         the        early  ...  None  None  None   \n",
       "24999     child           and          it        break  ...  None  None  None   \n",
       "\n",
       "       2492  2493  2494  2495  2496  2497 frst_nan  \n",
       "0      None  None  None  None  None  None      438  \n",
       "1      None  None  None  None  None  None      161  \n",
       "2      None  None  None  None  None  None      379  \n",
       "3      None  None  None  None  None  None      385  \n",
       "4      None  None  None  None  None  None      381  \n",
       "...     ...   ...   ...   ...   ...   ...      ...  \n",
       "24995  None  None  None  None  None  None       91  \n",
       "24996  None  None  None  None  None  None      182  \n",
       "24997  None  None  None  None  None  None      131  \n",
       "24998  None  None  None  None  None  None      206  \n",
       "24999  None  None  None  None  None  None      188  \n",
       "\n",
       "[25000 rows x 2499 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_fl = pd.concat([words,\n",
    "                      pd.Series(first_nan,\n",
    "                                name='frst_nan',\n",
    "                                dtype=int)\n",
    "                      .fillna(value=words.shape[1]-1)\n",
    "                      .astype(int)], axis=1)\n",
    "words_fl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_row(row, sntc_ln=100):\n",
    "    \"\"\"\n",
    "    From each row (review) take \n",
    "    the first and last sentence (word\n",
    "    count) as defined by sntc_ln.\n",
    "    \"\"\"\n",
    "    # get the first occurence of None\n",
    "    # for this row.\n",
    "    frst_nan = row['frst_nan']\n",
    "    # if review is less than two \n",
    "    # sentences long, take the\n",
    "    # columns up to 2 * sentence length\n",
    "    if frst_nan <= 2*sntc_ln:\n",
    "        return row.iloc[:int(2*sntc_ln)].values\n",
    "    # else ...\n",
    "    else:\n",
    "        # grab first sentence length\n",
    "        sen1 = row.iloc[:sntc_ln]\n",
    "        # grab the last sentence length\n",
    "        sen2 = row.iloc[frst_nan-sntc_ln-1:frst_nan-1]\n",
    "        return np.concatenate((sen1,sen2))\n",
    "\n",
    "def soft_get(w):\n",
    "    \"\"\"\n",
    "    Convert a single word to a \n",
    "    word vector as provided by\n",
    "    the loaded gensim model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # retrieve the word vector if it exists\n",
    "        return word_vectors[w]\n",
    "    except KeyError:\n",
    "        # fill the vector space with zeros otherwise\n",
    "        # - justified because we are summing the \n",
    "        #   word vectors in map_vectors\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "\n",
    "def map_vectors(row, take_mean=True):\n",
    "    \"\"\"\n",
    "    Convert a row of words (with some NaN's)\n",
    "    to the sum of these word vectors\n",
    "    according to the gensim model.\n",
    "    \"\"\"\n",
    "    if np.sum(row.notna()) == 0:\n",
    "        # if entirely zeros, return zeros\n",
    "        # - but this should be eliminated \n",
    "        #   at some point to avoid singular matrix\n",
    "        return np.zeros(word_vectors.vector_size)\n",
    "    if take_mean:\n",
    "        try:\n",
    "            # otherwise, return the mean of the \n",
    "            # word vectors\n",
    "            return np.mean(\n",
    "                row.loc[row.notna()].apply(soft_get)\n",
    "            )\n",
    "        except:\n",
    "            # if error return zeros\n",
    "            return np.zeros(word_vectors.vector_size)\n",
    "    else:\n",
    "        try:\n",
    "            # otherwise, return the sum of the \n",
    "            # word vectors\n",
    "            return np.sum(\n",
    "                row.loc[row.notna()].apply(soft_get)\n",
    "            )\n",
    "        except:\n",
    "            # if error return zeros\n",
    "            return np.zeros(word_vectors.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectSentences(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Create a class of inheritance from \n",
    "    BaseEstimator and TransformerMixin in\n",
    "    order to get the .fit and .transform\n",
    "    methods.\n",
    "    This will allow us to perform feature\n",
    "    engineering with these methods and\n",
    "    then use the class in a pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self, use_gensim=True, \n",
    "                 take_mean=True, \n",
    "                 stnd_rows=False, \n",
    "                 sntc_len=100): # no *args or **kargs\n",
    "        self.sntc_len = sntc_len # length of sentence to use for 1st and last\n",
    "        self.take_mean = take_mean # whether to take mean of sum of vectors for gensim\n",
    "        self.stnd_rows = stnd_rows # whether to standardize rows or not for gensim\n",
    "        self.use_gensim = use_gensim # whether of not to use gensim\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Do all the feature engineering\n",
    "        # we want to do here.\n",
    "        # In our case, the function was\n",
    "        # already defined. Just call it.\n",
    "        \n",
    "        # create the series where only\n",
    "        # the required # of words in each\n",
    "        # row are retained.\n",
    "        X_sntc = X.apply(shift_row, \n",
    "                         args=(self.sntc_len,), \n",
    "                         axis=1)\n",
    "        if self.use_gensim:\n",
    "            X_sntc = pd.DataFrame(X_sntc.to_list())\n",
    "        else:\n",
    "            X_sntc = pd.DataFrame(X_sntc)\n",
    "            X_sntc = X_sntc[0].agg(lambda x: ','.join(map(str, x)).replace(',',' ')).to_list()\n",
    "        \n",
    "        if self.use_gensim:\n",
    "            # Apply the word vector transformation\n",
    "            # using either the sum or mean of \n",
    "            # the word vectors.\n",
    "            X_sntc = pd.DataFrame(X_sntc.apply(map_vectors, \n",
    "                                               args=(self.take_mean,),\n",
    "                                               axis=1)\n",
    "                                  .tolist())\n",
    "            # Finally, take the MinMaxScaler of \n",
    "            # each row if called for.\n",
    "            X_sntc = X_sntc.to_numpy()\n",
    "            if self.stnd_rows:\n",
    "                scalar = MinMaxScaler()\n",
    "                scalar.fit(np.transpose(X_sntc))\n",
    "                X_sntc = scalar.transform(np.transpose(X_sntc))\n",
    "                X_sntc = np.transpose(X_sntc)\n",
    "        return X_sntc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the X and y and split into X_train and X_test variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = words_fl.copy()\n",
    "y = df.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define GridSearchCV parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('feat_eng', SelectSentences()),\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('logreg', LogisticRegression(n_jobs=4,\n",
    "                                  max_iter=2_000))\n",
    " ])\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        # Feature engineering params\n",
    "        'feat_eng__sntc_len': [50, 100, 300, 500, 600], # chosen 500\n",
    "        # the following were feature engineering parameters for \n",
    "        # Gensim but were not used in final cut\n",
    "        'feat_eng__use_gensim': [False],\n",
    "        'feat_eng__take_mean': [False], # only for gensim\n",
    "        'feat_eng__stnd_rows': [False], # only for gensim\n",
    "        \n",
    "        # TF-IDF params\n",
    "        'tfidf__max_df': [0.7, 0.8, 0.9, 0.95], # little influence\n",
    "        'tfidf__min_df': [1, 5], # little influence\n",
    "        'tfidf__max_features': [500, 1000, 5000], # significant influence\n",
    "        'tfidf__sublinear_tf': [True],  # significant influence\n",
    "        'tfidf__ngram_range': [(1,2)],  # useful in (2,2) format\n",
    "        'tfidf__stop_words': [None],\n",
    "        'tfidf__smooth_idf': [False],\n",
    "#        'tfidf__use_idf': [False],\n",
    "#        'tfidf__norm': ['l1'],\n",
    "#        'tfidf__strip_accents': ['ascii', 'unicode'],\n",
    "#        'logreg__l1_ratio': [0., 0.5, 1.0], # chose 0.5\n",
    "#        'logreg__l1_ratio': [0.5],\n",
    "        'logreg__penalty': ['l2'],\n",
    "        'logreg__C': [1, 1000, 1000000, 1000000000] # chose 1\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 480 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=4)]: Done 120 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=4)]: Done 280 tasks      | elapsed: 23.0min\n",
      "[Parallel(n_jobs=4)]: Done 504 tasks      | elapsed: 46.3min\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed: 93.0min\n",
      "[Parallel(n_jobs=4)]: Done 960 out of 960 | elapsed: 127.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat_eng__sntc_len': 500, 'feat_eng__stnd_rows': False, 'feat_eng__take_mean': False, 'feat_eng__use_gensim': False, 'logreg__C': 1, 'logreg__penalty': 'l2', 'tfidf__max_df': 0.95, 'tfidf__max_features': 5000, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 2), 'tfidf__smooth_idf': False, 'tfidf__stop_words': None, 'tfidf__sublinear_tf': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9028"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=2, n_jobs=4, verbose=3)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
